{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datamodule\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbprocess.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.all import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'https://raw.githubusercontent.com/Isaac-Flath/trading/main/data/eod-quotemedia.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CsvGetter:\n",
    "    def __init__(self,fpath): store_attr()\n",
    "    def __call__(self): return pd.read_csv(self.fpath, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CsvGetter(fpath)()\n",
    "test_eq(df.shape,(490737,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SizeSplitter:\n",
    "    def __init__(self,sizes=None): \n",
    "        if sizes is None:\n",
    "            self.sizes = L(('train',0.5),('valid',0.25),('test',0.25))\n",
    "        else: \n",
    "            sizes_sum = np.array([o[1] for o in sizes]).sum()\n",
    "            \n",
    "            try:test_close(sizes_sum, 1.)\n",
    "            except AssertionError: raise Exception('Your sizes must sum to 1')\n",
    "                \n",
    "            try:test_eq(['train','valid','test'],sizes.keys())\n",
    "            except AssertionError: raise Exception('You must have train, valid, and test sets')\n",
    "                \n",
    "            self.sizes = sizes\n",
    "\n",
    "        \n",
    "    def __call__(self,df):        \n",
    "        sizes = self.sizes\n",
    "        unique_dates = L(*df.date.unique()).sorted()\n",
    "\n",
    "        out = AttrDict()\n",
    "        \n",
    "        break_sz = int(len(unique_dates)*sizes[0][1])\n",
    "        out[sizes[0][0]] = df.loc[df.date <= unique_dates[break_sz]]\n",
    "        \n",
    "        _remainder_df = df.loc[df.date > unique_dates[break_sz]]\n",
    "        _remainder_dates = unique_dates[break_sz+1:]\n",
    "\n",
    "        break_sz = int(len(unique_dates)*sizes[1][1])\n",
    "        out[sizes[1][0]] = _remainder_df.loc[_remainder_df.date <= _remainder_dates[break_sz]]\n",
    "        out[sizes[2][0]] = _remainder_df.loc[_remainder_df.date > _remainder_dates[break_sz]]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CsvGetter(fpath)()\n",
    "dataset = SizeSplitter()(df)\n",
    "test_eq(dataset.train.shape,(242680, 3))\n",
    "test_eq(dataset.keys(),['train','valid','test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataModule:\n",
    "    def __init__(self, getter, splitter): \n",
    "        store_attr()\n",
    "        df = getter()\n",
    "        self.datasets = splitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(CsvGetter(fpath),SizeSplitter())\n",
    "test_eq(dm.datasets.train.shape,(242680, 3))\n",
    "test_eq(dm.datasets.keys(),['train','valid','test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
